{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) (Continued from the DataCleaning Notebook ... ) Modeling!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5806 entries, 0 to 5805\n",
      "Data columns (total 12 columns):\n",
      "Name                 5806 non-null object\n",
      "Location             5806 non-null object\n",
      "Year                 5806 non-null int64\n",
      "Kilometers_Driven    5806 non-null int64\n",
      "Is_Diesel            5806 non-null int64\n",
      "Is_Manual            5806 non-null int64\n",
      "Number_Owners        5806 non-null int64\n",
      "Mileage-kmpl         5806 non-null float64\n",
      "Engine-cc            5806 non-null int64\n",
      "Power-bhp            5806 non-null float64\n",
      "Seats                5806 non-null int64\n",
      "Price                5806 non-null float64\n",
      "dtypes: float64(3), int64(7), object(2)\n",
      "memory usage: 544.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#double checking this new cleaned data file looks as expected\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Kilometers_Driven</th>\n",
       "      <th>Is_Diesel</th>\n",
       "      <th>Is_Manual</th>\n",
       "      <th>Number_Owners</th>\n",
       "      <th>Mileage-kmpl</th>\n",
       "      <th>Engine-cc</th>\n",
       "      <th>Power-bhp</th>\n",
       "      <th>Seats</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hyundai Creta 1.6 CRDi SX Option</td>\n",
       "      <td>Pune</td>\n",
       "      <td>2015</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.67</td>\n",
       "      <td>1582</td>\n",
       "      <td>126.20</td>\n",
       "      <td>5</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Honda Jazz V</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2011</td>\n",
       "      <td>46000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.20</td>\n",
       "      <td>1199</td>\n",
       "      <td>88.70</td>\n",
       "      <td>5</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Maruti Ertiga VDI</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2012</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.77</td>\n",
       "      <td>1248</td>\n",
       "      <td>88.76</td>\n",
       "      <td>7</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Audi A4 New 2.0 TDI Multitronic</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>2013</td>\n",
       "      <td>40670</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.20</td>\n",
       "      <td>1968</td>\n",
       "      <td>140.80</td>\n",
       "      <td>5</td>\n",
       "      <td>17.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Nissan Micra Diesel XV</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2013</td>\n",
       "      <td>86999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.08</td>\n",
       "      <td>1461</td>\n",
       "      <td>63.10</td>\n",
       "      <td>5</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name    Location  Year  Kilometers_Driven  \\\n",
       "0  Hyundai Creta 1.6 CRDi SX Option        Pune  2015              41000   \n",
       "1                      Honda Jazz V     Chennai  2011              46000   \n",
       "2                 Maruti Ertiga VDI     Chennai  2012              87000   \n",
       "3   Audi A4 New 2.0 TDI Multitronic  Coimbatore  2013              40670   \n",
       "4            Nissan Micra Diesel XV      Jaipur  2013              86999   \n",
       "\n",
       "   Is_Diesel  Is_Manual  Number_Owners  Mileage-kmpl  Engine-cc  Power-bhp  \\\n",
       "0          1          1              1         19.67       1582     126.20   \n",
       "1          0          1              1         18.20       1199      88.70   \n",
       "2          1          1              1         20.77       1248      88.76   \n",
       "3          1          0              2         15.20       1968     140.80   \n",
       "4          1          1              1         23.08       1461      63.10   \n",
       "\n",
       "   Seats  Price  \n",
       "0      5  12.50  \n",
       "1      5   4.50  \n",
       "2      7   6.00  \n",
       "3      5  17.74  \n",
       "4      5   3.50  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Variables \n",
    "\n",
    "We have some catagorical variables, that won't play nice with our linear modeling, so first things first, let's set up some dummy variables for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mumbai        757\n",
       "Hyderabad     709\n",
       "Kochi         637\n",
       "Coimbatore    629\n",
       "Pune          581\n",
       "Delhi         535\n",
       "Kolkata       521\n",
       "Chennai       473\n",
       "Jaipur        400\n",
       "Bangalore     347\n",
       "Ahmedabad     217\n",
       "Name: Location, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many locations do we have? \n",
    "df['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are too many individual car types but, Brand might be an interesting factor to consider in the model.\n",
    "df['Brand'] = df['Name'].map(lambda x: x.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dummy variables for Location, Brand and Number of Seats. \n",
    "#Other variables are either already binary or continuous\n",
    "df_dummies = pd.get_dummies(df, columns = ['Brand', 'Location', 'Seats'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5806 entries, 0 to 5805\n",
      "Data columns (total 56 columns):\n",
      "Name                   5806 non-null object\n",
      "Year                   5806 non-null int64\n",
      "Kilometers_Driven      5806 non-null int64\n",
      "Is_Diesel              5806 non-null int64\n",
      "Is_Manual              5806 non-null int64\n",
      "Number_Owners          5806 non-null int64\n",
      "Mileage-kmpl           5806 non-null float64\n",
      "Engine-cc              5806 non-null int64\n",
      "Power-bhp              5806 non-null float64\n",
      "Price                  5806 non-null float64\n",
      "Brand_Audi             5806 non-null uint8\n",
      "Brand_BMW              5806 non-null uint8\n",
      "Brand_Bentley          5806 non-null uint8\n",
      "Brand_Chevrolet        5806 non-null uint8\n",
      "Brand_Datsun           5806 non-null uint8\n",
      "Brand_Fiat             5806 non-null uint8\n",
      "Brand_Force            5806 non-null uint8\n",
      "Brand_Ford             5806 non-null uint8\n",
      "Brand_Honda            5806 non-null uint8\n",
      "Brand_Hyundai          5806 non-null uint8\n",
      "Brand_ISUZU            5806 non-null uint8\n",
      "Brand_Isuzu            5806 non-null uint8\n",
      "Brand_Jaguar           5806 non-null uint8\n",
      "Brand_Jeep             5806 non-null uint8\n",
      "Brand_Lamborghini      5806 non-null uint8\n",
      "Brand_Land             5806 non-null uint8\n",
      "Brand_Mahindra         5806 non-null uint8\n",
      "Brand_Maruti           5806 non-null uint8\n",
      "Brand_Mercedes-Benz    5806 non-null uint8\n",
      "Brand_Mini             5806 non-null uint8\n",
      "Brand_Mitsubishi       5806 non-null uint8\n",
      "Brand_Nissan           5806 non-null uint8\n",
      "Brand_Porsche          5806 non-null uint8\n",
      "Brand_Renault          5806 non-null uint8\n",
      "Brand_Skoda            5806 non-null uint8\n",
      "Brand_Tata             5806 non-null uint8\n",
      "Brand_Toyota           5806 non-null uint8\n",
      "Brand_Volkswagen       5806 non-null uint8\n",
      "Brand_Volvo            5806 non-null uint8\n",
      "Location_Bangalore     5806 non-null uint8\n",
      "Location_Chennai       5806 non-null uint8\n",
      "Location_Coimbatore    5806 non-null uint8\n",
      "Location_Delhi         5806 non-null uint8\n",
      "Location_Hyderabad     5806 non-null uint8\n",
      "Location_Jaipur        5806 non-null uint8\n",
      "Location_Kochi         5806 non-null uint8\n",
      "Location_Kolkata       5806 non-null uint8\n",
      "Location_Mumbai        5806 non-null uint8\n",
      "Location_Pune          5806 non-null uint8\n",
      "Seats_4                5806 non-null uint8\n",
      "Seats_5                5806 non-null uint8\n",
      "Seats_6                5806 non-null uint8\n",
      "Seats_7                5806 non-null uint8\n",
      "Seats_8                5806 non-null uint8\n",
      "Seats_9                5806 non-null uint8\n",
      "Seats_10               5806 non-null uint8\n",
      "dtypes: float64(3), int64(6), object(1), uint8(46)\n",
      "memory usage: 714.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dummies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up our Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating our x and y for modeling\n",
    "y = df_dummies.Price\n",
    "X = df_dummies.drop(columns=['Name', 'Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting our data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Impute any missing values with median value from the X_train dataset using SimpleImputer\n",
    "impute = SimpleImputer(strategy='median')\n",
    "X_train_imputed = pd.DataFrame(impute.fit_transform(X_train))\n",
    "X_test_imputed = pd.DataFrame(impute.transform(X_test))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the train and test data\n",
    "ss = StandardScaler()\n",
    "X_train_imputed_scaled = ss.fit_transform(X_train_imputed)\n",
    "X_test_imputed_scaled = ss.transform(X_test_imputed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Price</td>      <th>  R-squared:         </th> <td>   0.792</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.789</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   302.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 07 Feb 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:27:30</td>     <th>  Log-Likelihood:    </th> <td> -13320.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4354</td>      <th>  AIC:               </th> <td>2.675e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4299</td>      <th>  BIC:               </th> <td>2.710e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    54</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    9.6103</td> <td>    0.079</td> <td>  122.191</td> <td> 0.000</td> <td>    9.456</td> <td>    9.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.9821</td> <td>    0.111</td> <td>   26.856</td> <td> 0.000</td> <td>    2.764</td> <td>    3.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.7972</td> <td>    0.099</td> <td>   -8.033</td> <td> 0.000</td> <td>   -0.992</td> <td>   -0.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.7622</td> <td>    0.128</td> <td>    5.943</td> <td> 0.000</td> <td>    0.511</td> <td>    1.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0636</td> <td>    0.119</td> <td>    0.536</td> <td> 0.592</td> <td>   -0.169</td> <td>    0.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -0.1432</td> <td>    0.089</td> <td>   -1.614</td> <td> 0.107</td> <td>   -0.317</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.6292</td> <td>    0.149</td> <td>   -4.220</td> <td> 0.000</td> <td>   -0.921</td> <td>   -0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.7405</td> <td>    0.271</td> <td>    2.733</td> <td> 0.006</td> <td>    0.209</td> <td>    1.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    4.3712</td> <td>    0.253</td> <td>   17.252</td> <td> 0.000</td> <td>    3.875</td> <td>    4.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0683</td> <td>    1.025</td> <td>   -0.067</td> <td> 0.947</td> <td>   -2.078</td> <td>    1.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0964</td> <td>    1.087</td> <td>   -0.089</td> <td> 0.929</td> <td>   -2.227</td> <td>    2.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0208</td> <td>    0.115</td> <td>    0.181</td> <td> 0.856</td> <td>   -0.204</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -1.2724</td> <td>    0.722</td> <td>   -1.763</td> <td> 0.078</td> <td>   -2.688</td> <td>    0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.4705</td> <td>    0.237</td> <td>   -1.981</td> <td> 0.048</td> <td>   -0.936</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.5983</td> <td>    0.335</td> <td>   -1.787</td> <td> 0.074</td> <td>   -1.255</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.3187</td> <td>    0.158</td> <td>   -2.015</td> <td> 0.044</td> <td>   -0.629</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   -1.7856</td> <td>    1.110</td> <td>   -1.609</td> <td> 0.108</td> <td>   -3.962</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   -2.8171</td> <td>    1.598</td> <td>   -1.762</td> <td> 0.078</td> <td>   -5.951</td> <td>    0.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   -3.4043</td> <td>    2.023</td> <td>   -1.683</td> <td> 0.092</td> <td>   -7.369</td> <td>    0.561</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -0.3037</td> <td>    0.137</td> <td>   -2.218</td> <td> 0.027</td> <td>   -0.572</td> <td>   -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.1501</td> <td>    0.112</td> <td>   -1.342</td> <td> 0.180</td> <td>   -0.369</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    0.5880</td> <td>    0.448</td> <td>    1.312</td> <td> 0.190</td> <td>   -0.291</td> <td>    1.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.3899</td> <td>    0.274</td> <td>   -1.421</td> <td> 0.155</td> <td>   -0.928</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    0.6944</td> <td>    0.115</td> <td>    6.018</td> <td> 0.000</td> <td>    0.468</td> <td>    0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    1.3500</td> <td>    0.529</td> <td>    2.553</td> <td> 0.011</td> <td>    0.313</td> <td>    2.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>   -2.5748</td> <td>    1.115</td> <td>   -2.310</td> <td> 0.021</td> <td>   -4.760</td> <td>   -0.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -3.0209</td> <td>    2.058</td> <td>   -1.468</td> <td> 0.142</td> <td>   -7.056</td> <td>    1.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    0.2161</td> <td>    1.182</td> <td>    0.183</td> <td> 0.855</td> <td>   -2.102</td> <td>    2.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.1271</td> <td>    0.327</td> <td>    0.388</td> <td> 0.698</td> <td>   -0.515</td> <td>    0.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>   -0.5679</td> <td>    0.355</td> <td>   -1.600</td> <td> 0.110</td> <td>   -1.264</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   -1.1127</td> <td>    0.647</td> <td>   -1.720</td> <td> 0.086</td> <td>   -2.381</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    0.6297</td> <td>    0.299</td> <td>    2.106</td> <td> 0.035</td> <td>    0.044</td> <td>    1.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   -1.4958</td> <td>    0.841</td> <td>   -1.779</td> <td> 0.075</td> <td>   -3.144</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -1.4593</td> <td>    0.869</td> <td>   -1.680</td> <td> 0.093</td> <td>   -3.163</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>   -1.8407</td> <td>    0.895</td> <td>   -2.057</td> <td> 0.040</td> <td>   -3.595</td> <td>   -0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>   -1.9480</td> <td>    1.345</td> <td>   -1.448</td> <td> 0.148</td> <td>   -4.585</td> <td>    0.689</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -2.1203</td> <td>    1.191</td> <td>   -1.780</td> <td> 0.075</td> <td>   -4.455</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   -0.3039</td> <td>    0.296</td> <td>   -1.027</td> <td> 0.305</td> <td>   -0.884</td> <td>    0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>    0.5163</td> <td>    0.125</td> <td>    4.138</td> <td> 0.000</td> <td>    0.272</td> <td>    0.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    0.4613</td> <td>    0.136</td> <td>    3.382</td> <td> 0.001</td> <td>    0.194</td> <td>    0.729</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.6748</td> <td>    0.149</td> <td>    4.532</td> <td> 0.000</td> <td>    0.383</td> <td>    0.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>   -0.0929</td> <td>    0.141</td> <td>   -0.659</td> <td> 0.510</td> <td>   -0.370</td> <td>    0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>    0.6810</td> <td>    0.152</td> <td>    4.492</td> <td> 0.000</td> <td>    0.384</td> <td>    0.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>    0.2863</td> <td>    0.131</td> <td>    2.177</td> <td> 0.030</td> <td>    0.028</td> <td>    0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>    0.0080</td> <td>    0.150</td> <td>    0.054</td> <td> 0.957</td> <td>   -0.285</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -0.2708</td> <td>    0.143</td> <td>   -1.897</td> <td> 0.058</td> <td>   -0.551</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>   -0.1504</td> <td>    0.158</td> <td>   -0.951</td> <td> 0.341</td> <td>   -0.460</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    0.2598</td> <td>    0.146</td> <td>    1.783</td> <td> 0.075</td> <td>   -0.026</td> <td>    0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -1.7888</td> <td>    0.224</td> <td>   -7.993</td> <td> 0.000</td> <td>   -2.228</td> <td>   -1.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>   -7.0523</td> <td>    0.603</td> <td>  -11.688</td> <td> 0.000</td> <td>   -8.235</td> <td>   -5.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>   -1.1712</td> <td>    0.141</td> <td>   -8.303</td> <td> 0.000</td> <td>   -1.448</td> <td>   -0.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   -5.6576</td> <td>    0.532</td> <td>  -10.641</td> <td> 0.000</td> <td>   -6.700</td> <td>   -4.615</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -2.6067</td> <td>    0.262</td> <td>   -9.941</td> <td> 0.000</td> <td>   -3.121</td> <td>   -2.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>   -0.3768</td> <td>    0.087</td> <td>   -4.328</td> <td> 0.000</td> <td>   -0.547</td> <td>   -0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -0.4016</td> <td>    0.091</td> <td>   -4.415</td> <td> 0.000</td> <td>   -0.580</td> <td>   -0.223</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3972.265</td> <th>  Durbin-Watson:     </th>  <td>   1.934</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>757938.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.735</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>67.204</td>  <th>  Cond. No.          </th>  <td>    129.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Price   R-squared:                       0.792\n",
       "Model:                            OLS   Adj. R-squared:                  0.789\n",
       "Method:                 Least Squares   F-statistic:                     302.6\n",
       "Date:                Fri, 07 Feb 2020   Prob (F-statistic):               0.00\n",
       "Time:                        10:27:30   Log-Likelihood:                -13320.\n",
       "No. Observations:                4354   AIC:                         2.675e+04\n",
       "Df Residuals:                    4299   BIC:                         2.710e+04\n",
       "Df Model:                          54                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          9.6103      0.079    122.191      0.000       9.456       9.765\n",
       "x1             2.9821      0.111     26.856      0.000       2.764       3.200\n",
       "x2            -0.7972      0.099     -8.033      0.000      -0.992      -0.603\n",
       "x3             0.7622      0.128      5.943      0.000       0.511       1.014\n",
       "x4             0.0636      0.119      0.536      0.592      -0.169       0.296\n",
       "x5            -0.1432      0.089     -1.614      0.107      -0.317       0.031\n",
       "x6            -0.6292      0.149     -4.220      0.000      -0.921      -0.337\n",
       "x7             0.7405      0.271      2.733      0.006       0.209       1.272\n",
       "x8             4.3712      0.253     17.252      0.000       3.875       4.868\n",
       "x9            -0.0683      1.025     -0.067      0.947      -2.078       1.941\n",
       "x10           -0.0964      1.087     -0.089      0.929      -2.227       2.034\n",
       "x11            0.0208      0.115      0.181      0.856      -0.204       0.245\n",
       "x12           -1.2724      0.722     -1.763      0.078      -2.688       0.143\n",
       "x13           -0.4705      0.237     -1.981      0.048      -0.936      -0.005\n",
       "x14           -0.5983      0.335     -1.787      0.074      -1.255       0.058\n",
       "x15           -0.3187      0.158     -2.015      0.044      -0.629      -0.009\n",
       "x16           -1.7856      1.110     -1.609      0.108      -3.962       0.391\n",
       "x17           -2.8171      1.598     -1.762      0.078      -5.951       0.317\n",
       "x18           -3.4043      2.023     -1.683      0.092      -7.369       0.561\n",
       "x19           -0.3037      0.137     -2.218      0.027      -0.572      -0.035\n",
       "x20           -0.1501      0.112     -1.342      0.180      -0.369       0.069\n",
       "x21            0.5880      0.448      1.312      0.190      -0.291       1.467\n",
       "x22           -0.3899      0.274     -1.421      0.155      -0.928       0.148\n",
       "x23            0.6944      0.115      6.018      0.000       0.468       0.921\n",
       "x24            1.3500      0.529      2.553      0.011       0.313       2.387\n",
       "x25           -2.5748      1.115     -2.310      0.021      -4.760      -0.390\n",
       "x26           -3.0209      2.058     -1.468      0.142      -7.056       1.014\n",
       "x27            0.2161      1.182      0.183      0.855      -2.102       2.534\n",
       "x28            0.1271      0.327      0.388      0.698      -0.515       0.769\n",
       "x29           -0.5679      0.355     -1.600      0.110      -1.264       0.128\n",
       "x30           -1.1127      0.647     -1.720      0.086      -2.381       0.156\n",
       "x31            0.6297      0.299      2.106      0.035       0.044       1.216\n",
       "x32           -1.4958      0.841     -1.779      0.075      -3.144       0.153\n",
       "x33           -1.4593      0.869     -1.680      0.093      -3.163       0.244\n",
       "x34           -1.8407      0.895     -2.057      0.040      -3.595      -0.086\n",
       "x35           -1.9480      1.345     -1.448      0.148      -4.585       0.689\n",
       "x36           -2.1203      1.191     -1.780      0.075      -4.455       0.215\n",
       "x37           -0.3039      0.296     -1.027      0.305      -0.884       0.276\n",
       "x38            0.5163      0.125      4.138      0.000       0.272       0.761\n",
       "x39            0.4613      0.136      3.382      0.001       0.194       0.729\n",
       "x40            0.6748      0.149      4.532      0.000       0.383       0.967\n",
       "x41           -0.0929      0.141     -0.659      0.510      -0.370       0.184\n",
       "x42            0.6810      0.152      4.492      0.000       0.384       0.978\n",
       "x43            0.2863      0.131      2.177      0.030       0.028       0.544\n",
       "x44            0.0080      0.150      0.054      0.957      -0.285       0.301\n",
       "x45           -0.2708      0.143     -1.897      0.058      -0.551       0.009\n",
       "x46           -0.1504      0.158     -0.951      0.341      -0.460       0.159\n",
       "x47            0.2598      0.146      1.783      0.075      -0.026       0.546\n",
       "x48           -1.7888      0.224     -7.993      0.000      -2.228      -1.350\n",
       "x49           -7.0523      0.603    -11.688      0.000      -8.235      -5.869\n",
       "x50           -1.1712      0.141     -8.303      0.000      -1.448      -0.895\n",
       "x51           -5.6576      0.532    -10.641      0.000      -6.700      -4.615\n",
       "x52           -2.6067      0.262     -9.941      0.000      -3.121      -2.093\n",
       "x53           -0.3768      0.087     -4.328      0.000      -0.547      -0.206\n",
       "x54           -0.4016      0.091     -4.415      0.000      -0.580      -0.223\n",
       "==============================================================================\n",
       "Omnibus:                     3972.265   Durbin-Watson:                   1.934\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           757938.050\n",
       "Skew:                           3.735   Prob(JB):                         0.00\n",
       "Kurtosis:                      67.204   Cond. No.                         129.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X_train_imputed_scaled)\n",
    "results = OLS(y_train, X).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of Normality\n",
    "There are four principal assumptions which justify the use of linear regression models for purposes of inference or prediction:\n",
    "\n",
    "(i) linearity and additivity of the relationship between dependent and independent variables:\n",
    "\n",
    "    (a) The expected value of dependent variable is a straight-line function of each independent variable, holding the others fixed.\n",
    "\n",
    "    (b) The slope of that line does not depend on the values of the other variables.\n",
    "\n",
    "    (c)  The effects of different independent variables on the expected value of the dependent variable are additive.\n",
    "\n",
    "(ii) statistical independence of the errors (in particular, no correlation between consecutive errors in the case of time series data)\n",
    "\n",
    "(iii) homoscedasticity (constant variance) of the errors\n",
    "\n",
    "    (a) versus time (in the case of time series data)\n",
    "\n",
    "    (b) versus the predictions\n",
    "\n",
    "    (c) versus any independent variable\n",
    "\n",
    "(iv) normality of the error distribution.\n",
    "\n",
    "Source: http://people.duke.edu/~rnau/testing.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So, let's check our model assumptions!\n",
    "#Q-Q Plot to check normality of residuals\n",
    "import scipy.stats as stats\n",
    "resid1 = results.resid\n",
    "fig = sm.graphics.qqplot(resid1, dist=stats.norm, line='45', fit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh ... this is really not great ... more tuning is need to continue with this model \n",
    "\n",
    "## 6) Code for Future Work\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7916985025917374\n",
      "Test r^2: 0.7733207062955831\n",
      "Training MSE: 26.59288921920093\n",
      "Test MSE: 28.3120881680343\n"
     ]
    }
   ],
   "source": [
    "#Using sklearn instead and inputting the X_train median for any missing values \n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute any missing values with median value from the X_train dataset using SimpleImputer\n",
    "impute = SimpleImputer(strategy='median')\n",
    "X_train_imputed = pd.DataFrame(impute.fit_transform(X_train))\n",
    "X_test_imputed = pd.DataFrame(impute.transform(X_test))\n",
    "\n",
    "# Fit the model\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Print R2 and MSE for training and test sets\n",
    "print('Training r^2:', linreg.score(X_train_imputed, y_train))\n",
    "print('Test r^2:', linreg.score(X_test_imputed, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg.predict(X_train_imputed)))\n",
    "print('Test MSE:', mean_squared_error(y_test, linreg.predict(X_test_imputed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.47241774e-01, -2.13219955e-05,  1.52942960e+00,  1.39930647e-01,\n",
       "       -3.20731235e-01, -1.45995157e-01,  1.24154829e-03,  8.12723086e-02,\n",
       "       -3.49603703e-01, -4.65909497e-01,  1.37000658e+00, -9.25056065e+00,\n",
       "       -1.09863061e+01, -9.59361585e+00, -1.21448733e+01, -8.41063498e+00,\n",
       "       -9.21782192e+00, -8.79467239e+00, -1.41730451e+01, -9.90699138e+00,\n",
       "        6.99340638e+00, -7.76619940e+00,  4.58265434e+01,  1.34980613e+01,\n",
       "       -1.20999934e+01, -7.66952873e+00,  9.58367232e-01,  2.09973541e+00,\n",
       "       -8.61531881e+00, -9.03949367e+00,  1.15419742e+01, -9.32788397e+00,\n",
       "       -8.80788320e+00, -1.07751544e+01, -7.57526567e+00, -9.30877897e+00,\n",
       "       -5.57007182e+00,  2.17502946e+00,  1.69458943e+00,  2.18893580e+00,\n",
       "       -3.19933427e-01,  2.12863994e+00,  1.10499676e+00,  2.58505845e-02,\n",
       "       -9.21116824e-01, -4.46474875e-01,  8.61962391e-01, -1.40268489e+01,\n",
       "       -1.91881921e+01, -1.77689666e+01, -1.78074721e+01, -1.76622011e+01,\n",
       "       -1.75826914e+01, -1.53064578e+01])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data with Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7916985025917368\n",
      "Test r^2: 0.773320706295679\n",
      "Training MSE: 26.592889219201005\n",
      "Test MSE: 28.31208816802232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the train and test data\n",
    "ss = StandardScaler()\n",
    "X_train_imputed_scaled = ss.fit_transform(X_train_imputed)\n",
    "X_test_imputed_scaled = ss.transform(X_test_imputed)\n",
    "\n",
    "# Fit the model \n",
    "linreg_norm = LinearRegression()\n",
    "linreg_norm.fit(X_train_imputed_scaled, y_train)\n",
    "\n",
    "# Print R2 and MSE for training and test sets\n",
    "print('Training r^2:', linreg_norm.score(X_train_imputed_scaled, y_train))\n",
    "print('Test r^2:', linreg_norm.score(X_test_imputed_scaled, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, linreg_norm.predict(X_train_imputed_scaled)))\n",
    "print('Test MSE:', mean_squared_error(y_test, linreg_norm.predict(X_test_imputed_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.98205356, -0.79717549,  0.76221164,  0.06360386, -0.14320013,\n",
       "       -0.6291614 ,  0.74047237,  4.37124465, -0.068289  , -0.09636624,\n",
       "        0.02076006, -1.27242798, -0.47049295, -0.59829183, -0.31868361,\n",
       "       -1.78563769, -2.81708609, -3.40427342, -0.30369258, -0.15012316,\n",
       "        0.58799523, -0.38986242,  0.69442126,  1.35004406, -2.574832  ,\n",
       "       -3.02086495,  0.21612254,  0.12705183, -0.567877  , -1.11267883,\n",
       "        0.6297356 , -1.49580624, -1.45934237, -1.8406926 , -1.948031  ,\n",
       "       -2.12025533, -0.30390577,  0.51631869,  0.46134139,  0.67478545,\n",
       "       -0.09292708,  0.68101929,  0.28626271,  0.00802178, -0.2707764 ,\n",
       "       -0.15037411,  0.2597985 , -1.78879789, -7.05227889, -1.17123785,\n",
       "       -5.65764636, -2.60671826, -0.3767527 , -0.40164415])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_norm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much of a difference, let's try some regularization and see if we can zero out any of these coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7912224264606891\n",
      "Test r^2: 0.7741654778825127\n",
      "Training MSE: 26.653667658004274\n",
      "Test MSE: 28.20657677676366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso = LassoCV(cv = 5) # Lasso is also known as the L1 norm \n",
    "lasso.fit(X_train_imputed_scaled, y_train)\n",
    "\n",
    "print('Training r^2:', lasso.score(X_train_imputed_scaled, y_train))\n",
    "print('Test r^2:', lasso.score(X_test_imputed_scaled, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train_imputed_scaled)))\n",
    "print('Test MSE:', mean_squared_error(y_test, lasso.predict(X_test_imputed_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.95605222, -0.79118464,  0.70395642,  0.02246527, -0.125099  ,\n",
       "       -0.55267695,  0.7537817 ,  4.4723364 ,  1.5437756 ,  1.59732866,\n",
       "        0.12479953, -0.10747433, -0.10066758, -0.06028988, -0.09061402,\n",
       "        0.        , -0.25619498, -0.14179329, -0.1108108 , -0.01514659,\n",
       "        1.27758783,  0.02374358,  0.85928643,  2.17397921, -0.78248406,\n",
       "        0.28533047,  2.09025414,  0.61653585, -0.00984318, -0.06488874,\n",
       "        1.07218635, -0.13222456, -0.06888534, -0.38828968,  0.19343517,\n",
       "       -0.18979089,  0.13865262,  0.47956886,  0.42086833,  0.633276  ,\n",
       "       -0.11643106,  0.63997379,  0.2436452 , -0.01549091, -0.29356258,\n",
       "       -0.19215732,  0.21001921, -1.27202948, -5.57132833, -0.89389168,\n",
       "       -4.35518023, -1.98181078, -0.27947522, -0.28295508])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the same again ... only zero'd one out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.7916978561949749\n",
      "Test r^2: 0.7733360033050645\n",
      "Training MSE: 26.59297174168738\n",
      "Test MSE: 28.3101775820515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge = RidgeCV(cv=5) # Ridge is also known as the L2 norm\n",
    "ridge.fit(X_train_imputed_scaled, y_train)\n",
    "\n",
    "print('Training r^2:', ridge.score(X_train_imputed_scaled, y_train))\n",
    "print('Test r^2:', ridge.score(X_test_imputed_scaled, y_test))\n",
    "print('Training MSE:', mean_squared_error(y_train, ridge.predict(X_train_imputed_scaled)))\n",
    "print('Test MSE:', mean_squared_error(y_test, ridge.predict(X_test_imputed_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.98162339, -0.79757941,  0.76208631,  0.06361115, -0.1427836 ,\n",
       "       -0.62909119,  0.74165491,  4.37033407,  0.04535168,  0.02397526,\n",
       "        0.02954018, -1.19249877, -0.44557662, -0.56201951, -0.30345448,\n",
       "       -1.66228416, -2.63943063, -3.17922007, -0.29124982, -0.14132822,\n",
       "        0.6369945 , -0.36063142,  0.70389612,  1.40812757, -2.45124764,\n",
       "       -2.79186087,  0.3473767 ,  0.16224195, -0.52966414, -1.04113245,\n",
       "        0.66164095, -1.40252063, -1.36303093, -1.74137992, -1.79879257,\n",
       "       -1.98784424, -0.27218879,  0.51620478,  0.46161381,  0.67476846,\n",
       "       -0.0929829 ,  0.68092905,  0.28612999,  0.0080533 , -0.27083309,\n",
       "       -0.15055925,  0.25961014, -1.78282396, -7.03490741, -1.16808284,\n",
       "       -5.64257544, -2.59978077, -0.37576022, -0.40046592])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Wow! Ok, so, given what we have seen, all these models are performing similarily, let's zip up all these coeffiencents into a dataframe to see what might be interesting to investigate further. \n",
    "\n",
    "### What variables are really influencing things here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Kilometers_Driven', 'Is_Diesel', 'Is_Manual', 'Number_Owners',\n",
       "       'Mileage-kmpl', 'Engine-cc', 'Power-bhp', 'Brand_Audi', 'Brand_BMW',\n",
       "       'Brand_Bentley', 'Brand_Chevrolet', 'Brand_Datsun', 'Brand_Fiat',\n",
       "       'Brand_Force', 'Brand_Ford', 'Brand_Honda', 'Brand_Hyundai',\n",
       "       'Brand_ISUZU', 'Brand_Isuzu', 'Brand_Jaguar', 'Brand_Jeep',\n",
       "       'Brand_Lamborghini', 'Brand_Land', 'Brand_Mahindra', 'Brand_Maruti',\n",
       "       'Brand_Mercedes-Benz', 'Brand_Mini', 'Brand_Mitsubishi', 'Brand_Nissan',\n",
       "       'Brand_Porsche', 'Brand_Renault', 'Brand_Skoda', 'Brand_Tata',\n",
       "       'Brand_Toyota', 'Brand_Volkswagen', 'Brand_Volvo', 'Location_Bangalore',\n",
       "       'Location_Chennai', 'Location_Coimbatore', 'Location_Delhi',\n",
       "       'Location_Hyderabad', 'Location_Jaipur', 'Location_Kochi',\n",
       "       'Location_Kolkata', 'Location_Mumbai', 'Location_Pune', 'Seats_4',\n",
       "       'Seats_5', 'Seats_6', 'Seats_7', 'Seats_8', 'Seats_9', 'Seats_10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variables</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Normalized</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>Ridge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Year</td>\n",
       "      <td>0.947242</td>\n",
       "      <td>2.982054</td>\n",
       "      <td>2.956052</td>\n",
       "      <td>2.981623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Kilometers_Driven</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.797175</td>\n",
       "      <td>-0.791185</td>\n",
       "      <td>-0.797579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Is_Diesel</td>\n",
       "      <td>1.529430</td>\n",
       "      <td>0.762212</td>\n",
       "      <td>0.703956</td>\n",
       "      <td>0.762086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Is_Manual</td>\n",
       "      <td>0.139931</td>\n",
       "      <td>0.063604</td>\n",
       "      <td>0.022465</td>\n",
       "      <td>0.063611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Number_Owners</td>\n",
       "      <td>-0.320731</td>\n",
       "      <td>-0.143200</td>\n",
       "      <td>-0.125099</td>\n",
       "      <td>-0.142784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Mileage-kmpl</td>\n",
       "      <td>-0.145995</td>\n",
       "      <td>-0.629161</td>\n",
       "      <td>-0.552677</td>\n",
       "      <td>-0.629091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Engine-cc</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.740472</td>\n",
       "      <td>0.753782</td>\n",
       "      <td>0.741655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Power-bhp</td>\n",
       "      <td>0.081272</td>\n",
       "      <td>4.371245</td>\n",
       "      <td>4.472336</td>\n",
       "      <td>4.370334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Brand_Audi</td>\n",
       "      <td>-0.349604</td>\n",
       "      <td>-0.068289</td>\n",
       "      <td>1.543776</td>\n",
       "      <td>0.045352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Brand_BMW</td>\n",
       "      <td>-0.465909</td>\n",
       "      <td>-0.096366</td>\n",
       "      <td>1.597329</td>\n",
       "      <td>0.023975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Brand_Bentley</td>\n",
       "      <td>1.370007</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>0.029540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Brand_Chevrolet</td>\n",
       "      <td>-9.250561</td>\n",
       "      <td>-1.272428</td>\n",
       "      <td>-0.107474</td>\n",
       "      <td>-1.192499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Brand_Datsun</td>\n",
       "      <td>-10.986306</td>\n",
       "      <td>-0.470493</td>\n",
       "      <td>-0.100668</td>\n",
       "      <td>-0.445577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Brand_Fiat</td>\n",
       "      <td>-9.593616</td>\n",
       "      <td>-0.598292</td>\n",
       "      <td>-0.060290</td>\n",
       "      <td>-0.562020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Brand_Force</td>\n",
       "      <td>-12.144873</td>\n",
       "      <td>-0.318684</td>\n",
       "      <td>-0.090614</td>\n",
       "      <td>-0.303454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Brand_Ford</td>\n",
       "      <td>-8.410635</td>\n",
       "      <td>-1.785638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.662284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Brand_Honda</td>\n",
       "      <td>-9.217822</td>\n",
       "      <td>-2.817086</td>\n",
       "      <td>-0.256195</td>\n",
       "      <td>-2.639431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Brand_Hyundai</td>\n",
       "      <td>-8.794672</td>\n",
       "      <td>-3.404273</td>\n",
       "      <td>-0.141793</td>\n",
       "      <td>-3.179220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Brand_ISUZU</td>\n",
       "      <td>-14.173045</td>\n",
       "      <td>-0.303693</td>\n",
       "      <td>-0.110811</td>\n",
       "      <td>-0.291250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Brand_Isuzu</td>\n",
       "      <td>-9.906991</td>\n",
       "      <td>-0.150123</td>\n",
       "      <td>-0.015147</td>\n",
       "      <td>-0.141328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Brand_Jaguar</td>\n",
       "      <td>6.993406</td>\n",
       "      <td>0.587995</td>\n",
       "      <td>1.277588</td>\n",
       "      <td>0.636994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Brand_Jeep</td>\n",
       "      <td>-7.766199</td>\n",
       "      <td>-0.389862</td>\n",
       "      <td>0.023744</td>\n",
       "      <td>-0.360631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Brand_Lamborghini</td>\n",
       "      <td>45.826543</td>\n",
       "      <td>0.694421</td>\n",
       "      <td>0.859286</td>\n",
       "      <td>0.703896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Brand_Land</td>\n",
       "      <td>13.498061</td>\n",
       "      <td>1.350044</td>\n",
       "      <td>2.173979</td>\n",
       "      <td>1.408128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Brand_Mahindra</td>\n",
       "      <td>-12.099993</td>\n",
       "      <td>-2.574832</td>\n",
       "      <td>-0.782484</td>\n",
       "      <td>-2.451248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Brand_Maruti</td>\n",
       "      <td>-7.669529</td>\n",
       "      <td>-3.020865</td>\n",
       "      <td>0.285330</td>\n",
       "      <td>-2.791861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Brand_Mercedes-Benz</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>0.216123</td>\n",
       "      <td>2.090254</td>\n",
       "      <td>0.347377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Brand_Mini</td>\n",
       "      <td>2.099735</td>\n",
       "      <td>0.127052</td>\n",
       "      <td>0.616536</td>\n",
       "      <td>0.162242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Brand_Mitsubishi</td>\n",
       "      <td>-8.615319</td>\n",
       "      <td>-0.567877</td>\n",
       "      <td>-0.009843</td>\n",
       "      <td>-0.529664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Brand_Nissan</td>\n",
       "      <td>-9.039494</td>\n",
       "      <td>-1.112679</td>\n",
       "      <td>-0.064889</td>\n",
       "      <td>-1.041132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Brand_Porsche</td>\n",
       "      <td>11.541974</td>\n",
       "      <td>0.629736</td>\n",
       "      <td>1.072186</td>\n",
       "      <td>0.661641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Brand_Renault</td>\n",
       "      <td>-9.327884</td>\n",
       "      <td>-1.495806</td>\n",
       "      <td>-0.132225</td>\n",
       "      <td>-1.402521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Brand_Skoda</td>\n",
       "      <td>-8.807883</td>\n",
       "      <td>-1.459342</td>\n",
       "      <td>-0.068885</td>\n",
       "      <td>-1.363031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Brand_Tata</td>\n",
       "      <td>-10.775154</td>\n",
       "      <td>-1.840693</td>\n",
       "      <td>-0.388290</td>\n",
       "      <td>-1.741380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Brand_Toyota</td>\n",
       "      <td>-7.575266</td>\n",
       "      <td>-1.948031</td>\n",
       "      <td>0.193435</td>\n",
       "      <td>-1.798793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Brand_Volkswagen</td>\n",
       "      <td>-9.308779</td>\n",
       "      <td>-2.120255</td>\n",
       "      <td>-0.189791</td>\n",
       "      <td>-1.987844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Brand_Volvo</td>\n",
       "      <td>-5.570072</td>\n",
       "      <td>-0.303906</td>\n",
       "      <td>0.138653</td>\n",
       "      <td>-0.272189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Location_Bangalore</td>\n",
       "      <td>2.175029</td>\n",
       "      <td>0.516319</td>\n",
       "      <td>0.479569</td>\n",
       "      <td>0.516205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Location_Chennai</td>\n",
       "      <td>1.694589</td>\n",
       "      <td>0.461341</td>\n",
       "      <td>0.420868</td>\n",
       "      <td>0.461614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Location_Coimbatore</td>\n",
       "      <td>2.188936</td>\n",
       "      <td>0.674785</td>\n",
       "      <td>0.633276</td>\n",
       "      <td>0.674768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Location_Delhi</td>\n",
       "      <td>-0.319933</td>\n",
       "      <td>-0.092927</td>\n",
       "      <td>-0.116431</td>\n",
       "      <td>-0.092983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Location_Hyderabad</td>\n",
       "      <td>2.128640</td>\n",
       "      <td>0.681019</td>\n",
       "      <td>0.639974</td>\n",
       "      <td>0.680929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>Location_Jaipur</td>\n",
       "      <td>1.104997</td>\n",
       "      <td>0.286263</td>\n",
       "      <td>0.243645</td>\n",
       "      <td>0.286130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>Location_Kochi</td>\n",
       "      <td>0.025851</td>\n",
       "      <td>0.008022</td>\n",
       "      <td>-0.015491</td>\n",
       "      <td>0.008053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Location_Kolkata</td>\n",
       "      <td>-0.921117</td>\n",
       "      <td>-0.270776</td>\n",
       "      <td>-0.293563</td>\n",
       "      <td>-0.270833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>Location_Mumbai</td>\n",
       "      <td>-0.446475</td>\n",
       "      <td>-0.150374</td>\n",
       "      <td>-0.192157</td>\n",
       "      <td>-0.150559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>Location_Pune</td>\n",
       "      <td>0.861962</td>\n",
       "      <td>0.259799</td>\n",
       "      <td>0.210019</td>\n",
       "      <td>0.259610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>Seats_4</td>\n",
       "      <td>-14.026849</td>\n",
       "      <td>-1.788798</td>\n",
       "      <td>-1.272029</td>\n",
       "      <td>-1.782824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>Seats_5</td>\n",
       "      <td>-19.188192</td>\n",
       "      <td>-7.052279</td>\n",
       "      <td>-5.571328</td>\n",
       "      <td>-7.034907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>Seats_6</td>\n",
       "      <td>-17.768967</td>\n",
       "      <td>-1.171238</td>\n",
       "      <td>-0.893892</td>\n",
       "      <td>-1.168083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>Seats_7</td>\n",
       "      <td>-17.807472</td>\n",
       "      <td>-5.657646</td>\n",
       "      <td>-4.355180</td>\n",
       "      <td>-5.642575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>Seats_8</td>\n",
       "      <td>-17.662201</td>\n",
       "      <td>-2.606718</td>\n",
       "      <td>-1.981811</td>\n",
       "      <td>-2.599781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>Seats_9</td>\n",
       "      <td>-17.582691</td>\n",
       "      <td>-0.376753</td>\n",
       "      <td>-0.279475</td>\n",
       "      <td>-0.375760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>Seats_10</td>\n",
       "      <td>-15.306458</td>\n",
       "      <td>-0.401644</td>\n",
       "      <td>-0.282955</td>\n",
       "      <td>-0.400466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Variables      Naive  Normalized     Lasso     Ridge\n",
       "0                  Year   0.947242    2.982054  2.956052  2.981623\n",
       "1     Kilometers_Driven  -0.000021   -0.797175 -0.791185 -0.797579\n",
       "2             Is_Diesel   1.529430    0.762212  0.703956  0.762086\n",
       "3             Is_Manual   0.139931    0.063604  0.022465  0.063611\n",
       "4         Number_Owners  -0.320731   -0.143200 -0.125099 -0.142784\n",
       "5          Mileage-kmpl  -0.145995   -0.629161 -0.552677 -0.629091\n",
       "6             Engine-cc   0.001242    0.740472  0.753782  0.741655\n",
       "7             Power-bhp   0.081272    4.371245  4.472336  4.370334\n",
       "8            Brand_Audi  -0.349604   -0.068289  1.543776  0.045352\n",
       "9             Brand_BMW  -0.465909   -0.096366  1.597329  0.023975\n",
       "10        Brand_Bentley   1.370007    0.020760  0.124800  0.029540\n",
       "11      Brand_Chevrolet  -9.250561   -1.272428 -0.107474 -1.192499\n",
       "12         Brand_Datsun -10.986306   -0.470493 -0.100668 -0.445577\n",
       "13           Brand_Fiat  -9.593616   -0.598292 -0.060290 -0.562020\n",
       "14          Brand_Force -12.144873   -0.318684 -0.090614 -0.303454\n",
       "15           Brand_Ford  -8.410635   -1.785638  0.000000 -1.662284\n",
       "16          Brand_Honda  -9.217822   -2.817086 -0.256195 -2.639431\n",
       "17        Brand_Hyundai  -8.794672   -3.404273 -0.141793 -3.179220\n",
       "18          Brand_ISUZU -14.173045   -0.303693 -0.110811 -0.291250\n",
       "19          Brand_Isuzu  -9.906991   -0.150123 -0.015147 -0.141328\n",
       "20         Brand_Jaguar   6.993406    0.587995  1.277588  0.636994\n",
       "21           Brand_Jeep  -7.766199   -0.389862  0.023744 -0.360631\n",
       "22    Brand_Lamborghini  45.826543    0.694421  0.859286  0.703896\n",
       "23           Brand_Land  13.498061    1.350044  2.173979  1.408128\n",
       "24       Brand_Mahindra -12.099993   -2.574832 -0.782484 -2.451248\n",
       "25         Brand_Maruti  -7.669529   -3.020865  0.285330 -2.791861\n",
       "26  Brand_Mercedes-Benz   0.958367    0.216123  2.090254  0.347377\n",
       "27           Brand_Mini   2.099735    0.127052  0.616536  0.162242\n",
       "28     Brand_Mitsubishi  -8.615319   -0.567877 -0.009843 -0.529664\n",
       "29         Brand_Nissan  -9.039494   -1.112679 -0.064889 -1.041132\n",
       "30        Brand_Porsche  11.541974    0.629736  1.072186  0.661641\n",
       "31        Brand_Renault  -9.327884   -1.495806 -0.132225 -1.402521\n",
       "32          Brand_Skoda  -8.807883   -1.459342 -0.068885 -1.363031\n",
       "33           Brand_Tata -10.775154   -1.840693 -0.388290 -1.741380\n",
       "34         Brand_Toyota  -7.575266   -1.948031  0.193435 -1.798793\n",
       "35     Brand_Volkswagen  -9.308779   -2.120255 -0.189791 -1.987844\n",
       "36          Brand_Volvo  -5.570072   -0.303906  0.138653 -0.272189\n",
       "37   Location_Bangalore   2.175029    0.516319  0.479569  0.516205\n",
       "38     Location_Chennai   1.694589    0.461341  0.420868  0.461614\n",
       "39  Location_Coimbatore   2.188936    0.674785  0.633276  0.674768\n",
       "40       Location_Delhi  -0.319933   -0.092927 -0.116431 -0.092983\n",
       "41   Location_Hyderabad   2.128640    0.681019  0.639974  0.680929\n",
       "42      Location_Jaipur   1.104997    0.286263  0.243645  0.286130\n",
       "43       Location_Kochi   0.025851    0.008022 -0.015491  0.008053\n",
       "44     Location_Kolkata  -0.921117   -0.270776 -0.293563 -0.270833\n",
       "45      Location_Mumbai  -0.446475   -0.150374 -0.192157 -0.150559\n",
       "46        Location_Pune   0.861962    0.259799  0.210019  0.259610\n",
       "47              Seats_4 -14.026849   -1.788798 -1.272029 -1.782824\n",
       "48              Seats_5 -19.188192   -7.052279 -5.571328 -7.034907\n",
       "49              Seats_6 -17.768967   -1.171238 -0.893892 -1.168083\n",
       "50              Seats_7 -17.807472   -5.657646 -4.355180 -5.642575\n",
       "51              Seats_8 -17.662201   -2.606718 -1.981811 -2.599781\n",
       "52              Seats_9 -17.582691   -0.376753 -0.279475 -0.375760\n",
       "53             Seats_10 -15.306458   -0.401644 -0.282955 -0.400466"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting all these coefficients into pandas Dataframe, to see which variables are influencing our model. \n",
    "coef_list = list(zip(X_train.columns, linreg.coef_, linreg_norm.coef_, lasso.coef_, ridge.coef_))\n",
    "coef_df = pd.DataFrame(coef_list, columns = ['Variables', 'Naive', 'Normalized', 'Lasso', 'Ridge'])\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
